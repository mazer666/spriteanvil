/**
 * src/lib/ai/providers.ts
 * -----------------------------------------------------------------------------
 * ## AI PROVIDERS (Noob Guide)
 * 
 * Think of this as the "AI Translator".
 * 
 * ## JARGON GLOSSARY
 * 1. PROVIDER: A company that runs AI models (like OpenAI or Stability).
 * 2. ENDPOINT: The "Address" where we send our requests.
 * 3. MODEL ID: The name of the specific AI "Worker" (e.g., "dall-e-3").
 * 4. API KEY: A secret password that tells the provider who is 
 *    paying for the generated art.
 * 
 * ## VISUAL FLOW (Mermaid)
 * ```mermaid
 * graph LR
 *   REQ[Generic AI Request] --> ROUTE{Check Provider ID}
 *   ROUTE -- OpenAI --> OAPI[Build DALL-E JSON]
 *   ROUTE -- Stability --> SAPI[Build SDXL JSON]
 *   ROUTE -- Other --> HAPI[Build Custom JSON]
 *   OAPI --> FETCH[Fetch API]
 *   SAPI --> FETCH
 *   HAPI --> FETCH
 *   FETCH --> RES[Return Image URL]
 * ```
 */

export type AIProviderId = "openai-dalle3" | "stability-ai" | "hugging-face" | "openrouter";

export type AIRequest = {
  prompt: string;
  negativePrompt?: string;
  width: number;
  height: number;
  seed?: number;
  steps?: number;
};

export type AIResult = {
  images: string[];
  provider: AIProviderId;
};

export type AIProvider = {
  id: AIProviderId;
  label: string;
  supportsInpaint: boolean;
  supportsVariations: boolean;
  generate: (request: AIRequest, apiKey: string) => Promise<AIResult>;
};

function notImplemented(provider: AIProviderId): never {
  throw new Error(`Provider ${provider} is not implemented yet.`);
}

export const PROVIDERS: AIProvider[] = [
  {
    id: "openai-dalle3",
    label: "OpenAI DALLÂ·E 3",
    supportsInpaint: true,
    supportsVariations: true,
    generate: async () => notImplemented("openai-dalle3"),
  },
  {
    id: "stability-ai",
    label: "Stability AI",
    supportsInpaint: true,
    supportsVariations: true,
    generate: async () => notImplemented("stability-ai"),
  },
  {
    id: "hugging-face",
    label: "Hugging Face",
    supportsInpaint: false,
    supportsVariations: true,
    generate: async () => notImplemented("hugging-face"),
  },
  {
    id: "openrouter",
    label: "OpenRouter",
    supportsInpaint: true,
    supportsVariations: true,
    generate: async (request: AIRequest, apiKey: string): Promise<AIResult> => {
      // WHAT: Sends a request to OpenRouter (Universal AI API).
      // WHY: This allows SpriteAnvil to stay provider-agnostic.
      // ðŸ› ï¸ NOOB TIP: We use 'fetch' to talk to the remote server.

      const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${apiKey}`,
          "Content-Type": "application/json",
          "HTTP-Referer": "https://spriteanvil.com", // Optional, for OpenRouter rankings
          "X-Title": "SpriteAnvil",
        },
        body: JSON.stringify({
          model: "openai/dall-e-3", // Default model, can be made configurable later
          prompt: request.prompt,
          n: 1,
          size: `${request.width}x${request.height}`,
          // OpenRouter specific payload structure for images varies,
          // but for chat-based image generation models:
          messages: [
            {
              role: "user",
              content: request.prompt,
            }
          ]
        }),
      });

      if (!response.ok) {
        const error = await response.json().catch(() => ({}));
        throw new Error(`OpenRouter Error: ${error?.error?.message || response.statusText}`);
      }

      const data = await response.json();
      // Handle standard OpenRouter image response or URL result
      const imageUrl = data.choices?.[0]?.message?.content || data.images?.[0];

      if (!imageUrl) {
        throw new Error("No image generated by OpenRouter.");
      }

      return {
        images: [imageUrl],
        provider: "openrouter",
      };
    },
  },
];

export function getProvider(id: AIProviderId): AIProvider | undefined {
  return PROVIDERS.find((provider) => provider.id === id);
}
